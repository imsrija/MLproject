{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVoyBpAkqpGnMvGdvnge1Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imsrija/MLproject/blob/main/Untitled37.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSNKiLmM1nZh",
        "outputId": "eb0a716f-058c-424f-a4db-0c682e4e1253"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python-headless) (2.0.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.14.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy_loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.6.15)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from soundfile) (2.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,059 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,572 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,750 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,347 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,036 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,726 kB]\n",
            "Fetched 27.9 MB in 6s (4,872 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python-headless\n",
        "!pip install pydub\n",
        "!pip install librosa\n",
        "!pip install soundfile\n",
        "!apt-get update\n",
        "!apt-get install -y ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import tempfile\n",
        "import subprocess\n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import detect_nonsilent\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from google.colab import files\n",
        "\n",
        "def extract_motion_video_and_voice(input_video_path, output_video_path, output_audio_path):\n",
        "    \"\"\"\n",
        "    Extract both motion frames for video and voice-only segments for audio\n",
        "    \"\"\"\n",
        "    # First extract and process the audio\n",
        "    voice_segments = extract_voice_only_audio(input_video_path, output_audio_path)\n",
        "\n",
        "    # Then extract motion frames for video\n",
        "    motion_video, motion_timelines = extract_motion_video(input_video_path, output_video_path)\n",
        "\n",
        "    return {\n",
        "        'motion_video': motion_video,\n",
        "        'motion_timelines': motion_timelines,\n",
        "        'voice_audio': output_audio_path,\n",
        "        'voice_segments': voice_segments\n",
        "    }\n",
        "\n",
        "def extract_voice_only_audio(input_video_path, output_audio_path):\n",
        "    \"\"\"\n",
        "    Extract only the voice segments from the input video's audio\n",
        "    \"\"\"\n",
        "    print(\"\\nExtracting and processing audio from video...\")\n",
        "\n",
        "    # Create a temporary audio file\n",
        "    temp_audio = tempfile.NamedTemporaryFile(suffix='.wav', delete=False).name\n",
        "\n",
        "    # Extract audio from video using ffmpeg\n",
        "    subprocess.call(['ffmpeg', '-i', input_video_path, '-q:a', '0', '-map', 'a', temp_audio, '-y'],\n",
        "                   stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "    # Load audio file\n",
        "    print(\"Loading audio and detecting voice segments...\")\n",
        "    audio = AudioSegment.from_file(temp_audio, format=\"wav\")\n",
        "\n",
        "    # Detect non-silent parts\n",
        "    # min_silence_len: minimum silence length in ms\n",
        "    # silence_thresh: silence threshold in dB\n",
        "    non_silent_chunks = detect_nonsilent(audio,\n",
        "                                        min_silence_len=500,  # 500ms\n",
        "                                        silence_thresh=-35)   # -35dB\n",
        "\n",
        "    # Convert to seconds for reporting\n",
        "    voice_segments = [(start/1000, end/1000) for start, end in non_silent_chunks]\n",
        "\n",
        "    print(f\"Found {len(voice_segments)} voice segments\")\n",
        "\n",
        "    # Create a new audio file with only the voice segments\n",
        "    output_audio = AudioSegment.empty()\n",
        "    for start_ms, end_ms in non_silent_chunks:\n",
        "        output_audio += audio[start_ms:end_ms]\n",
        "\n",
        "    # Export the voice-only audio\n",
        "    output_audio.export(output_audio_path, format=\"wav\")\n",
        "\n",
        "    # Calculate statistics\n",
        "    total_audio_duration = len(audio) / 1000  # in seconds\n",
        "    voice_audio_duration = len(output_audio) / 1000  # in seconds\n",
        "\n",
        "    print(f\"Original audio duration: {total_audio_duration:.2f} seconds\")\n",
        "    print(f\"Voice-only audio duration: {voice_audio_duration:.2f} seconds\")\n",
        "    print(f\"Voice percentage: {(voice_audio_duration/total_audio_duration)*100:.2f}%\\n\")\n",
        "\n",
        "    # Print timeline details\n",
        "    print(\"Voice Segment Timelines:\")\n",
        "    for i, (start, end) in enumerate(voice_segments, 1):\n",
        "        duration = end - start\n",
        "        print(f\"Voice {i}: {start:.2f}s - {end:.2f}s (Duration: {duration:.2f}s)\")\n",
        "\n",
        "    # Cleanup temporary files\n",
        "    os.unlink(temp_audio)\n",
        "\n",
        "    return voice_segments\n",
        "\n",
        "def extract_motion_video(input_video_path, output_video_path):\n",
        "    \"\"\"\n",
        "    Extract frames with significant motion using OpenCV only\n",
        "    \"\"\"\n",
        "    # Open input video\n",
        "    cap = cv2.VideoCapture(input_video_path)\n",
        "\n",
        "    # Get video properties\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Video writer for motion frames\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "    # Motion detection parameters\n",
        "    MOVEMENT_THRESHOLD = 5000  # Adjust based on your video\n",
        "    MOTION_WINDOW = int(fps * 0.5)  # 0.5-second window\n",
        "    BUFFER_FRAMES = int(fps * 0.2)  # 0.2s buffer\n",
        "\n",
        "    # Variables for tracking\n",
        "    motion_frames = []\n",
        "    prev_frame = None\n",
        "    motion_in_progress = False\n",
        "    motion_count = 0\n",
        "    frame_count = 0\n",
        "    motion_timelines = []\n",
        "    current_motion = {'start_time': None, 'end_time': None}\n",
        "    recent_frames_buffer = []\n",
        "\n",
        "    print(\"Processing video for motion...\")\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Keep buffer of recent frames\n",
        "        recent_frames_buffer.append(frame.copy())\n",
        "        if len(recent_frames_buffer) > BUFFER_FRAMES * 2:\n",
        "            recent_frames_buffer.pop(0)\n",
        "\n",
        "        # Convert to grayscale for motion detection\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
        "\n",
        "        # Compare with previous frame\n",
        "        if prev_frame is not None:\n",
        "            # Calculate difference\n",
        "            frame_diff = cv2.absdiff(prev_frame, gray)\n",
        "            thresh = cv2.threshold(frame_diff, 25, 255, cv2.THRESH_BINARY)[1]\n",
        "            thresh = cv2.dilate(thresh, None, iterations=2)\n",
        "\n",
        "            # Find contours in threshold image\n",
        "            contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "            # Calculate total motion area\n",
        "            motion_area = sum([cv2.contourArea(c) for c in contours])\n",
        "\n",
        "            # Check if motion exceeds threshold\n",
        "            is_motion_frame = motion_area > MOVEMENT_THRESHOLD\n",
        "\n",
        "            # Handle motion detection\n",
        "            if is_motion_frame:\n",
        "                if not motion_in_progress:\n",
        "                    motion_in_progress = True\n",
        "                    current_motion['start_time'] = frame_count / fps\n",
        "                    motion_count += 1\n",
        "\n",
        "                    # Add buffer frames\n",
        "                    buffer_start = max(0, len(recent_frames_buffer) - BUFFER_FRAMES)\n",
        "                    for buffer_frame in recent_frames_buffer[buffer_start:-1]:\n",
        "                        annotated_frame = buffer_frame.copy()\n",
        "                        buffer_time = (frame_count - (len(recent_frames_buffer) - buffer_start)) / fps\n",
        "                        cv2.putText(annotated_frame, f\"Original Time: {buffer_time:.2f}s\", (10, height - 20),\n",
        "                                  cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "                        motion_frames.append(annotated_frame)\n",
        "\n",
        "                # Add current frame with annotation\n",
        "                annotated_frame = frame.copy()\n",
        "                current_time = frame_count / fps\n",
        "                cv2.putText(annotated_frame, f\"Motion {motion_count} at {current_time:.2f}s\", (width - 240, 30),\n",
        "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "                cv2.putText(annotated_frame, f\"Original Time: {current_time:.2f}s\", (10, height - 20),\n",
        "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "\n",
        "                current_motion['end_time'] = current_time\n",
        "                motion_frames.append(annotated_frame)\n",
        "            else:\n",
        "                if motion_in_progress:\n",
        "                    # Add buffer frames after motion\n",
        "                    buffer_count = 0\n",
        "                    for i in range(BUFFER_FRAMES):\n",
        "                        if frame_count + i < total_frames and buffer_count < BUFFER_FRAMES:\n",
        "                            ret_ahead, frame_ahead = cap.read()\n",
        "                            if ret_ahead:\n",
        "                                annotated_frame = frame_ahead.copy()\n",
        "                                buffer_time = (frame_count + buffer_count) / fps\n",
        "                                cv2.putText(annotated_frame, f\"Original Time: {buffer_time:.2f}s\", (10, height - 20),\n",
        "                                          cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "                                motion_frames.append(annotated_frame)\n",
        "                                buffer_count += 1\n",
        "\n",
        "                    # Reposition video\n",
        "                    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_count + buffer_count)\n",
        "\n",
        "                    # Add timeline\n",
        "                    motion_timelines.append({\n",
        "                        'start_time': current_motion['start_time'],\n",
        "                        'end_time': current_motion['end_time'],\n",
        "                        'duration': current_motion['end_time'] - current_motion['start_time']\n",
        "                    })\n",
        "\n",
        "                    # Reset motion tracking\n",
        "                    current_motion = {'start_time': None, 'end_time': None}\n",
        "                    motion_in_progress = False\n",
        "\n",
        "        # Update previous frame\n",
        "        prev_frame = gray\n",
        "\n",
        "        # Progress tracking\n",
        "        frame_count += 1\n",
        "        if frame_count % 100 == 0:\n",
        "            print(f\"Processed {frame_count}/{total_frames} frames\")\n",
        "\n",
        "    # Write motion frames to output\n",
        "    print(f\"Writing {len(motion_frames)} motion frames to output video...\")\n",
        "    for frame in motion_frames:\n",
        "        out.write(frame)\n",
        "\n",
        "    # Clean up\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    # Print statistics\n",
        "    input_duration = total_frames / fps\n",
        "    output_duration = len(motion_frames) / fps\n",
        "    print(f\"\\nVideo Processing Complete:\")\n",
        "    print(f\"Input Duration: {input_duration:.2f}s\")\n",
        "    print(f\"Motion Video Duration: {output_duration:.2f}s\")\n",
        "    print(f\"Percentage of Motion Frames: {(output_duration/input_duration)*100:.2f}%\")\n",
        "\n",
        "    # Print timelines\n",
        "    print(\"\\nMotion Timelines:\")\n",
        "    for i, timeline in enumerate(motion_timelines, 1):\n",
        "        print(f\"Motion {i}: {timeline['start_time']:.2f}s - {timeline['end_time']:.2f}s (Duration: {timeline['duration']:.2f}s)\")\n",
        "\n",
        "    return output_video_path, motion_timelines\n",
        "\n",
        "def main():\n",
        "    print(\"Please upload your interview video:\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # Get the filename of the uploaded video\n",
        "    input_video_path = list(uploaded.keys())[0]\n",
        "    output_video_path = 'motion_video_only.mp4'\n",
        "    output_audio_path = 'voice_only_audio.wav'\n",
        "\n",
        "    # Extract motion frames with timelines and voice audio\n",
        "    results = extract_motion_video_and_voice(input_video_path, output_video_path, output_audio_path)\n",
        "\n",
        "    # Download the results\n",
        "    files.download(output_video_path)\n",
        "    files.download(output_audio_path)\n",
        "\n",
        "    print(\"\\nProcessing complete! Both files are available for download.\")\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-2p5uipz1yrX",
        "outputId": "720986c9-78a8-4ce3-8664-a520e7c23894"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your interview video:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6f9983f2-dd15-4c79-a4a7-0600c56af600\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6f9983f2-dd15-4c79-a4a7-0600c56af600\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving WhatsApp Video 2025-04-02 at 12.59.30 AM.mp4 to WhatsApp Video 2025-04-02 at 12.59.30 AM.mp4\n",
            "\n",
            "Extracting and processing audio from video...\n",
            "Loading audio and detecting voice segments...\n",
            "Found 31 voice segments\n",
            "Original audio duration: 127.39 seconds\n",
            "Voice-only audio duration: 90.52 seconds\n",
            "Voice percentage: 71.06%\n",
            "\n",
            "Voice Segment Timelines:\n",
            "Voice 1: 0.00s - 4.62s (Duration: 4.62s)\n",
            "Voice 2: 5.20s - 5.76s (Duration: 0.56s)\n",
            "Voice 3: 7.93s - 8.37s (Duration: 0.44s)\n",
            "Voice 4: 9.33s - 12.64s (Duration: 3.31s)\n",
            "Voice 5: 14.50s - 14.54s (Duration: 0.04s)\n",
            "Voice 6: 16.83s - 21.54s (Duration: 4.71s)\n",
            "Voice 7: 22.54s - 26.29s (Duration: 3.75s)\n",
            "Voice 8: 27.41s - 30.36s (Duration: 2.96s)\n",
            "Voice 9: 31.96s - 35.18s (Duration: 3.22s)\n",
            "Voice 10: 35.92s - 38.27s (Duration: 2.36s)\n",
            "Voice 11: 39.74s - 41.34s (Duration: 1.60s)\n",
            "Voice 12: 42.37s - 46.15s (Duration: 3.78s)\n",
            "Voice 13: 47.52s - 55.57s (Duration: 8.04s)\n",
            "Voice 14: 56.25s - 56.47s (Duration: 0.22s)\n",
            "Voice 15: 57.12s - 63.56s (Duration: 6.43s)\n",
            "Voice 16: 64.41s - 67.43s (Duration: 3.02s)\n",
            "Voice 17: 68.04s - 75.93s (Duration: 7.90s)\n",
            "Voice 18: 76.77s - 77.42s (Duration: 0.65s)\n",
            "Voice 19: 79.38s - 84.41s (Duration: 5.03s)\n",
            "Voice 20: 84.97s - 86.39s (Duration: 1.42s)\n",
            "Voice 21: 87.38s - 90.62s (Duration: 3.25s)\n",
            "Voice 22: 91.25s - 94.71s (Duration: 3.45s)\n",
            "Voice 23: 95.38s - 99.01s (Duration: 3.63s)\n",
            "Voice 24: 99.77s - 103.97s (Duration: 4.19s)\n",
            "Voice 25: 104.63s - 108.56s (Duration: 3.93s)\n",
            "Voice 26: 109.09s - 110.74s (Duration: 1.65s)\n",
            "Voice 27: 111.36s - 112.44s (Duration: 1.08s)\n",
            "Voice 28: 115.47s - 120.29s (Duration: 4.82s)\n",
            "Voice 29: 121.16s - 121.19s (Duration: 0.02s)\n",
            "Voice 30: 122.50s - 122.86s (Duration: 0.36s)\n",
            "Voice 31: 124.09s - 124.15s (Duration: 0.06s)\n",
            "Processing video for motion...\n",
            "Processed 100/3822 frames\n",
            "Processed 200/3822 frames\n",
            "Processed 300/3822 frames\n",
            "Processed 400/3822 frames\n",
            "Processed 500/3822 frames\n",
            "Processed 600/3822 frames\n",
            "Processed 700/3822 frames\n",
            "Processed 800/3822 frames\n",
            "Processed 900/3822 frames\n",
            "Processed 1000/3822 frames\n",
            "Processed 1100/3822 frames\n",
            "Processed 1200/3822 frames\n",
            "Processed 1300/3822 frames\n",
            "Processed 1400/3822 frames\n",
            "Processed 1500/3822 frames\n",
            "Processed 1600/3822 frames\n",
            "Processed 1700/3822 frames\n",
            "Processed 1800/3822 frames\n",
            "Processed 1900/3822 frames\n",
            "Processed 2000/3822 frames\n",
            "Processed 2100/3822 frames\n",
            "Processed 2200/3822 frames\n",
            "Processed 2300/3822 frames\n",
            "Processed 2400/3822 frames\n",
            "Processed 2500/3822 frames\n",
            "Processed 2600/3822 frames\n",
            "Processed 2700/3822 frames\n",
            "Processed 2800/3822 frames\n",
            "Processed 2900/3822 frames\n",
            "Processed 3000/3822 frames\n",
            "Processed 3100/3822 frames\n",
            "Processed 3200/3822 frames\n",
            "Processed 3300/3822 frames\n",
            "Processed 3400/3822 frames\n",
            "Processed 3500/3822 frames\n",
            "Processed 3600/3822 frames\n",
            "Processed 3700/3822 frames\n",
            "Processed 3800/3822 frames\n",
            "Writing 531 motion frames to output video...\n",
            "\n",
            "Video Processing Complete:\n",
            "Input Duration: 127.39s\n",
            "Motion Video Duration: 17.70s\n",
            "Percentage of Motion Frames: 13.89%\n",
            "\n",
            "Motion Timelines:\n",
            "Motion 1: 1.70s - 1.73s (Duration: 0.03s)\n",
            "Motion 2: 1.80s - 1.93s (Duration: 0.13s)\n",
            "Motion 3: 2.37s - 2.37s (Duration: 0.00s)\n",
            "Motion 4: 2.77s - 2.77s (Duration: 0.00s)\n",
            "Motion 5: 2.83s - 2.97s (Duration: 0.13s)\n",
            "Motion 6: 3.03s - 3.10s (Duration: 0.07s)\n",
            "Motion 7: 5.30s - 5.37s (Duration: 0.07s)\n",
            "Motion 8: 5.73s - 5.73s (Duration: 0.00s)\n",
            "Motion 9: 6.03s - 6.17s (Duration: 0.13s)\n",
            "Motion 10: 6.23s - 6.37s (Duration: 0.13s)\n",
            "Motion 11: 6.43s - 6.57s (Duration: 0.13s)\n",
            "Motion 12: 6.63s - 6.63s (Duration: 0.00s)\n",
            "Motion 13: 7.23s - 7.37s (Duration: 0.13s)\n",
            "Motion 14: 7.43s - 7.50s (Duration: 0.07s)\n",
            "Motion 15: 13.83s - 13.93s (Duration: 0.10s)\n",
            "Motion 16: 14.00s - 14.13s (Duration: 0.13s)\n",
            "Motion 17: 14.33s - 14.33s (Duration: 0.00s)\n",
            "Motion 18: 14.40s - 14.47s (Duration: 0.07s)\n",
            "Motion 19: 14.67s - 14.73s (Duration: 0.07s)\n",
            "Motion 20: 14.80s - 14.83s (Duration: 0.03s)\n",
            "Motion 21: 16.30s - 16.30s (Duration: 0.00s)\n",
            "Motion 22: 22.06s - 22.06s (Duration: 0.00s)\n",
            "Motion 23: 25.60s - 25.60s (Duration: 0.00s)\n",
            "Motion 24: 39.40s - 39.40s (Duration: 0.00s)\n",
            "Motion 25: 41.53s - 41.53s (Duration: 0.00s)\n",
            "Motion 26: 48.93s - 48.93s (Duration: 0.00s)\n",
            "Motion 27: 51.59s - 51.59s (Duration: 0.00s)\n",
            "Motion 28: 66.53s - 66.53s (Duration: 0.00s)\n",
            "Motion 29: 69.63s - 69.63s (Duration: 0.00s)\n",
            "Motion 30: 83.42s - 83.42s (Duration: 0.00s)\n",
            "Motion 31: 85.66s - 85.66s (Duration: 0.00s)\n",
            "Motion 32: 90.79s - 90.79s (Duration: 0.00s)\n",
            "Motion 33: 94.62s - 94.62s (Duration: 0.00s)\n",
            "Motion 34: 108.25s - 108.25s (Duration: 0.00s)\n",
            "Motion 35: 111.62s - 111.62s (Duration: 0.00s)\n",
            "Motion 36: 114.02s - 114.09s (Duration: 0.07s)\n",
            "Motion 37: 114.15s - 114.29s (Duration: 0.13s)\n",
            "Motion 38: 114.35s - 114.42s (Duration: 0.07s)\n",
            "Motion 39: 122.35s - 122.35s (Duration: 0.00s)\n",
            "Motion 40: 125.45s - 125.45s (Duration: 0.00s)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f96bc00a-4d45-4a0b-95cc-15745e17d211\", \"motion_video_only.mp4\", 3268299)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_60601124-44b1-48db-a721-7b82d1728b1f\", \"voice_only_audio.wav\", 15966900)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing complete! Both files are available for download.\n"
          ]
        }
      ]
    }
  ]
}